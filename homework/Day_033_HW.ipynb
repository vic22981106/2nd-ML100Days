{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 模型的泛化能力 (generalization) 是指什麼？\n",
    "\n",
    "所謂的generalization的意思就是model在沒看過的資料上的表現，那如何衡量model的generalization呢？就直接計算model在沒看過的資料上預測的error，這樣的error我們稱為generalization error，算法就跟在計算training error一樣。當我們在訓練模型的時候常常會比較training error以及generalization error之間變化趨勢。當我們將增加model capacity常常會看到training error下降，generalization error一開始也跟著下降，但是generalization並不會一直隨著model capacity增加而一直的下降，反而在超過某一個capacity之後就會開始飆高，這就是所謂的overfitting，也就是model 複雜程度已經高到學到很多training data 特有的特性，比如說在training data的資料大致上呈現一個二次曲線的分佈但是具有一定的bias，使得資料並不是晚整的落在曲線上而是在在二次曲線的上下擺動著，所謂的overfitting就是model開始學到這些bias，而導致在另外一群的data上(validation data)的表現是差的。\n",
    "\n",
    "2. 分類問題與回歸問題分別可用的目標函數有哪些？\n",
    "\n",
    "分類問題的loss function常見的是去最大化log-likelihodd function，也就是找一組model parameter，使得log-likelihood function的值愈大愈好，經過數學式子證明後，求解maximun likelihood function的過程中其實也等同於去minimize model prediction result與ground truth之間的cross entropy loss。可以想像的是在計算ground truth data與training data之間的機率分布的差異，而在衡量機率與機率之間的距離的時候若是用誤差平方的話可能不是那麼的恰當，反而是基於information field所提到的cross entropy loss ; 另外minize Cross entropy loss其實也等同於去minimize ground truth data與training data之間的KL divergence(一種機率之間距離的定義：可以想像是在使用正確的或者是training data(可能是假的)的機率分佈產生兩種編碼系統，那麼這兩種機率分佈平均的編碼長度之差異就是所謂的KL divergence。也就是說若是使用錯誤的機率分佈，產生出來的編碼系統相較於正確的機率產生的編碼系統來說多半是比較沒有效率的，而當今天training data的機率分佈與真正的資料分布是一樣的話，KL divergence就為零。關於這方面的解釋若解釋得不好也麻煩指證謝謝。)\n",
    "\n",
    "再來是回歸問題的目標函數。我認為回歸問題的目標函數應該相對簡單。因為回歸問題的目的就是curve fitting，要如何衡量curve 有沒有fit的很好很直觀的就是計算預測結果與實際結果的差距，常用的loss function是MSE, MAE，當然因為只是在算數值與數值的差距，可以由自己喜好去定義regression 的loss function。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
