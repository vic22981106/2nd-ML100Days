{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nDATA_ROOT = \"../input/\"\ntraining_data= pd.read_csv(os.path.join(DATA_ROOT,'train_offline.csv'))\ntesting_data = pd.read_csv(os.path.join(DATA_ROOT,'test_offline.csv'))\ntesting_data = testing_data[~testing_data.Coupon_id.isna()]\ntesting_data.reset_index(drop=True, inplace=True)\nprint(training_data.shape)\nprint(testing_data.shape)\ntraining_data.head()","execution_count":1,"outputs":[{"output_type":"stream","text":"(1160742, 7)\n(306313, 6)\n","name":"stdout"},{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"   User_id  Merchant_id     ...      Date_received        Date\n0  1439408         2632     ...                NaN  20160217.0\n1  1439408         2632     ...         20160217.0         NaN\n2  1439408         2632     ...         20160319.0         NaN\n3  1832624         3381     ...         20160429.0         NaN\n4  2029232         3381     ...         20160129.0         NaN\n\n[5 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_id</th>\n      <th>Merchant_id</th>\n      <th>Coupon_id</th>\n      <th>Discount_rate</th>\n      <th>Distance</th>\n      <th>Date_received</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1439408</td>\n      <td>2632</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>20160217.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1439408</td>\n      <td>2632</td>\n      <td>8591.0</td>\n      <td>20:1</td>\n      <td>0.0</td>\n      <td>20160217.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1439408</td>\n      <td>2632</td>\n      <td>1078.0</td>\n      <td>20:1</td>\n      <td>0.0</td>\n      <td>20160319.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1832624</td>\n      <td>3381</td>\n      <td>7610.0</td>\n      <td>200:20</td>\n      <td>0.0</td>\n      <td>20160429.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2029232</td>\n      <td>3381</td>\n      <td>11951.0</td>\n      <td>200:20</td>\n      <td>1.0</td>\n      <td>20160129.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## generate ground-truth data\n\"\"\"\nAccording to the definition, \n1) buy with coupon within (include) 15 days ==> 1\n2) buy with coupon but out of 15 days ==> 0\n3) buy without coupon ==> -1 (we don't care)\n\"\"\"\ndef label(row):\n    if np.isnan(row['Date_received']):\n        return -1\n    if not np.isnan(row['Date']):\n        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n        if td <= pd.Timedelta(15, 'D'):\n            return 1\n    return 0\n\ntraining_data[\"label\"] = training_data.apply(label, axis=1)\ntraining_data[\"label\"].value_counts()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":" 0    710665\n-1    413773\n 1     36304\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate features - weekday acquired coupon\ndef getWeekday(row):\n    if (np.isnan(row)) or (row==-1):\n        return row\n    else:\n        return pd.to_datetime(row, format = \"%Y%m%d\").dayofweek+1 # add one to make it from 0~6 -> 1~7\n    \ntraining_data['weekday'] = training_data['Date_received'].apply(getWeekday)\ntesting_data['weekday'] = testing_data['Date_received'].apply(getWeekday)\n\n# weekday_type (weekend = 1)\ntraining_data['weekday_type'] = training_data['weekday'].astype('float').apply(lambda x : 1 if x > 5 else 0 ) # apply to trainset\ntesting_data['weekday_type'] = testing_data['weekday'].astype('float').apply(lambda x : 1 if x > 5 else 0 ) # apply to testset","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate features - coupon discount and distance\ndef getDiscountType(row):\n    if row == 'null':\n        return 'null'\n    elif ':' in row:\n        return 1\n    else:\n        return 1\n\ndef convertRate(row):\n    \"\"\"Convert discount to rate\"\"\"\n    if row == 'null':\n        return 1.0\n    elif ':' in row:\n        rows = row.split(':')\n        return 1.0 - float(rows[1])/float(rows[0])\n    else:\n        return float(row)\n# def convertRate(row):\n#     \"\"\"Convert discount to rate\"\"\"\n#     if row == 'NAN':\n#         return 0\n#     elif ':' in row:\n#         rows = row.split(':')\n#         return float(rows[1])/float(rows[0])\n#     else:\n#         return 1-float(row)\n\ndef getDiscountMan(row):\n    if ':' in row:\n        rows = row.split(':')\n        return int(rows[0])\n    else:\n        return 0\n\ndef getDiscountJian(row):\n    if ':' in row:\n        rows = row.split(':')\n        return int(rows[1])\n    else:\n        return 0\n\ndef processData(df):\n    \n    # convert discunt_rate\n    df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n    \n    # convert distance\n    df.loc[df.Distance.isna(), \"Distance\"] = 100\n    return df\n\ntraining_data = processData(training_data)\ntesting_data = processData(testing_data)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.loc[training_data.discount_rate.isna(), \"discount_rate\"] = 1\ntraining_data.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   User_id  Merchant_id      ...       discount_jian discount_type\n0  1439408         2632      ...                   0             1\n1  1439408         2632      ...                   1             1\n2  1439408         2632      ...                   1             1\n3  1832624         3381      ...                  20             1\n4  2029232         3381      ...                  20             1\n\n[5 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_id</th>\n      <th>Merchant_id</th>\n      <th>Coupon_id</th>\n      <th>Discount_rate</th>\n      <th>Distance</th>\n      <th>Date_received</th>\n      <th>Date</th>\n      <th>label</th>\n      <th>weekday</th>\n      <th>weekday_type</th>\n      <th>discount_rate</th>\n      <th>discount_man</th>\n      <th>discount_jian</th>\n      <th>discount_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1439408</td>\n      <td>2632</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>20160217.0</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1439408</td>\n      <td>2632</td>\n      <td>8591.0</td>\n      <td>20:1</td>\n      <td>0.0</td>\n      <td>20160217.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0.95</td>\n      <td>20</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1439408</td>\n      <td>2632</td>\n      <td>1078.0</td>\n      <td>20:1</td>\n      <td>0.0</td>\n      <td>20160319.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0.95</td>\n      <td>20</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1832624</td>\n      <td>3381</td>\n      <td>7610.0</td>\n      <td>200:20</td>\n      <td>0.0</td>\n      <td>20160429.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>0.90</td>\n      <td>200</td>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2029232</td>\n      <td>3381</td>\n      <td>11951.0</td>\n      <td>200:20</td>\n      <td>1.0</td>\n      <td>20160129.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>0.90</td>\n      <td>200</td>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.discount_jian.value_counts()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"0      441232\n5      278240\n10     199749\n20     117648\n30      86224\n1       32412\n50       5228\n100         9\nName: discount_jian, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data.Distance.value_counts()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"0.0      135755\n1.0       48858\n100.0     36177\n10.0      22765\n2.0       20236\n3.0       12870\n4.0        9003\n5.0        6376\n6.0        4905\n7.0        3755\n8.0        3007\n9.0        2606\nName: Distance, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate training set and validation set:\n\ndef split_train_valid(row, date_cut=\"20160416\"):\n    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n    return is_train\n    \n# training_set = training_data[(training_data['label'] != -1) & (training_data['Distance'] != 100)].copy()\ntraining_set = training_data[(training_data['label'] != -1) & (training_data['Distance'] != 100)]\ntraining_set[\"is_train\"] = training_set[\"Date_received\"].apply(split_train_valid)\ntraining = training_set[training_set[\"is_train\"]]\nvalidation = training_set[~training_set[\"is_train\"]]\ntraining.reset_index(drop=True, inplace=True)\nvalidation.reset_index(drop=True, inplace=True)\nprint(\"Train size: {}, #positive: {}\".format(len(training), training[\"label\"].sum()))\nprint(\"Valid size: {}, #positive: {}\".format(len(validation), validation[\"label\"].sum()))","execution_count":8,"outputs":[{"output_type":"stream","text":"Train size: 605834, #positive: 29102\nValid size: 71309, #positive: 3412\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  if __name__ == '__main__':\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training.head()\ndiscount_rate = np.asarray(training['discount_rate'])\ndiscount_man = np.asarray(training['discount_man']) # normalize to 0 ~ 1\ndiscount_jian = np.asarray(training['discount_jian'])   # normalize to 0 ~ 1\ndiscount_type = np.asarray(training['discount_type']) \nweekday_type = np.asarray(training['weekday_type'])\ndistance = np.asarray(training['Distance'])      # normalize to 0 ~ 10\n\nx_train = np.dstack((discount_type, discount_rate, discount_man, discount_jian, weekday_type,distance))\nx_train = np.squeeze(x_train)\ny_train = np.asarray(training['label'])\nprint(y_train.shape)\nprint(x_train.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(605834,)\n(605834, 6)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation.head()\ndiscount_rate_validation = np.asarray(validation['discount_rate'])\ndiscount_man_validation = np.asarray(validation['discount_man'])\ndiscount_jian_validation = np.asarray(validation['discount_jian'])\ndiscount_type_validation = np.asarray(validation['discount_type'])\nweekday_type_validation = np.asarray(validation['weekday_type'])\ndistance_validation = np.asarray(validation['Distance'])\n\nx_val = np.dstack((discount_type_validation ,discount_rate_validation, discount_man_validation,discount_jian_validation, weekday_type_validation,distance_validation))\nx_val = np.squeeze(x_val)\ny_val = np.asarray(validation['label'])\nprint(y_val.shape)\nprint(x_val.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(71309,)\n(71309, 6)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom keras.utils.np_utils import to_categorical\n\nclass Coupon(nn.Module):\n    def __init__(self):\n        super(Coupon, self).__init__()\n        \n        #fully-connected neural network\n        #layer1\n        self.layer1=nn.Sequential(\n        nn.Linear(in_features=6, out_features=16, bias =True),\n        nn.LeakyReLU())\n        \n        #layer2\n        self.layer2=nn.Sequential(\n        nn.Linear(in_features=16, out_features=16, bias =True),\n        nn.LeakyReLU())\n        \n        #layer3\n        self.layer3=nn.Sequential(\n        nn.Linear(in_features=16, out_features=16, bias =True),\n        nn.LeakyReLU())\n        \n        #layer4\n        self.layer4=nn.Sequential(\n        nn.Linear(in_features=16, out_features=2, bias =True),\n        nn.Sigmoid())\n        \n    def forward(self, x):\n        x = torch.cuda.FloatTensor(x)\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        \n        return out","execution_count":11,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Coupon()\nmodel.cuda()\n\nx_train = torch.cuda.FloatTensor(x_train)\ny_train = torch.cuda.FloatTensor(y_train)\n\ny_label = to_categorical(y_train.detach().cpu())\ny_label = torch.cuda.FloatTensor(y_label)\n\n\nx_val = torch.cuda.FloatTensor(x_val)\ny_val = torch.cuda.FloatTensor(y_val)\ny_val_label = to_categorical(y_val.detach().cpu())\ny_val_label = torch.cuda.FloatTensor(y_val_label)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = 50\nlearning_rate = 0.001\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate) #weight_decay=5e-5)\nbatch_size=8192\nacc_train=[]\nacc_test=[]\n\n\nfor epoch in range(epoch):\n    \n    index = np.arange(0,605833,1)\n    np.random.shuffle(index)\n    \n    for i in range(80):\n        #training \n        model.train()\n        inputs = x_train[index[i*batch_size : i*batch_size+batch_size]]\n        label = y_label[index[i*batch_size : i*batch_size+batch_size]]\n        Label = y_train[index[i*batch_size : i*batch_size+batch_size]]\n\n        inputs = Variable(inputs)\n        label = Variable(label)\n        \n        #optimization and update parameters\n        optimizer.zero_grad()\n        y_pred = model.forward(inputs)\n        loss = criterion(y_pred, label)\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    with torch.no_grad():\n        #all training data\n        inputs = x_train\n        label = y_label\n        Label = y_train\n        y_pred = model.forward(inputs)\n    \n    \n        #all esting data\n        inputs_test = x_val\n        label_test = y_val_label\n        Label_test = y_val\n        y_pred_test = model.forward(inputs_test)\n    \n        correct_train=0\n        wrong_train=0\n        correct_test=0\n        wrong_test=0\n    \n        _, predicted1 = torch.max(y_pred.data, 1)\n        _, predicted2 = torch.max(y_pred_test.data, 1)\n\n        for n in range(605834):\n            if (predicted1[n] == int(Label[n])):\n                correct_train +=1\n            else:\n                wrong_train +=1\n    \n        for q in range(71309):\n            if (predicted2[q]==int(Label_test[q])):\n                correct_test +=1\n            else:\n                wrong_test +=1\n    \n    acc1 = round(correct_train/ (correct_train + wrong_train) *100,3)\n    acc2 = round(correct_test/ (correct_test + wrong_test) *100,3)\n    acc_train.append(acc1)\n    acc_test.append(acc2)\n\n    print(epoch, round(loss.item(),4), acc1, acc2)\n","execution_count":13,"outputs":[{"output_type":"stream","text":"0 nan 95.196 95.215\n1 nan 95.196 95.215\n2 nan 95.196 95.215\n3 nan 95.196 95.215\n4 nan 95.196 95.215\n5 nan 95.196 95.215\n6 nan 95.196 95.215\n7 nan 95.196 95.215\n8 nan 95.196 95.215\n9 nan 95.196 95.215\n10 nan 95.196 95.215\n11 nan 95.196 95.215\n12 nan 95.196 95.215\n13 nan 95.196 95.215\n14 nan 95.196 95.215\n15 nan 95.196 95.215\n16 nan 95.196 95.215\n17 nan 95.196 95.215\n18 nan 95.196 95.215\n19 nan 95.196 95.215\n20 nan 95.196 95.215\n21 nan 95.196 95.215\n22 nan 95.196 95.215\n23 nan 95.196 95.215\n24 nan 95.196 95.215\n25 nan 95.196 95.215\n26 nan 95.196 95.215\n27 nan 95.196 95.215\n28 nan 95.196 95.215\n29 nan 95.196 95.215\n30 nan 95.196 95.215\n31 nan 95.196 95.215\n32 nan 95.196 95.215\n33 nan 95.196 95.215\n34 nan 95.196 95.215\n35 nan 95.196 95.215\n36 nan 95.196 95.215\n37 nan 95.196 95.215\n38 nan 95.196 95.215\n39 nan 95.196 95.215\n40 nan 95.196 95.215\n41 nan 95.196 95.215\n42 nan 95.196 95.215\n43 nan 95.196 95.215\n44 nan 95.196 95.215\n45 nan 95.196 95.215\n46 nan 95.196 95.215\n47 nan 95.196 95.215\n48 nan 95.196 95.215\n49 nan 95.196 95.215\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nepoch = np.arange(0,50,1)\nTrain =plt.plot(epoch, acc_train, linestyle='solid',label=\"Training\")\nVal =plt.plot(epoch, acc_test, linestyle='solid',label=\"Validation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Coupon prediction accuracy\",fontsize=12)\nplt.legend()\nplt.savefig('./test.png')\n\nnp.save(\"./training.npy\", acc_train)\nnp.save(\"./validation.npy\", acc_test)\n\nplt.show()","execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score\n\ny_val_label =y_val_label.detach().cpu()\ny_val_label = np.asarray(y_val_label)\n# print(y_val_label.shape)\n\ny_pred_test = y_pred_test.detach().cpu()\ny_pred_test = np.asarray(y_pred_test)\n# print(y_pred_test.shape)\n\npredicted2 = predicted2.detach().cpu()\npredicted2 = np.asarray(predicted2)\n\nauc_score = roc_auc_score(y_true=y_val_label[:,1], y_score=y_pred_test[:,1])\nacc = accuracy_score(y_true=y_val_label[:,1], y_pred=predicted2)\n\nprint(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))","execution_count":15,"outputs":[{"output_type":"stream","text":"Validation AUC: 0.786, Accuracy: 0.952\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"discount_rate_test = np.asarray(testing_data['discount_rate'])\ndiscount_man_test = np.asarray(testing_data['discount_man']) # normalize to 0 ~ 1\ndiscount_jian_test = np.asarray(testing_data['discount_jian'])   # normalize to 0 ~ 1\ndiscount_type_test = np.asarray(testing_data['discount_type']) \nweekday_type_test = np.asarray(testing_data['weekday_type'])\ndistance_test = np.asarray(testing_data['Distance'])        # normalize to 0 ~ 10\n\nx_test = np.dstack((discount_type_test, discount_rate_test, discount_man_test, discount_jian_test, weekday_type_test,distance_test))\nx_test = np.squeeze(x_test)\n\nprint(x_test.shape)\n\n\ntargetset = testing_data.copy()\nprint(targetset.shape)\ntargetset = targetset[~targetset.Coupon_id.isna()]\ntargetset.reset_index(drop=True, inplace=True)\n\n\ny_test_pred = model.forward(x_test)\ntest1 = targetset.copy()\nprint(y_test_pred.shape)\nprint(test1.shape)\ny_test_pred = y_test_pred.detach().cpu().numpy()\nprint(y_test_pred)\ntest1['pred_prob'] = y_test_pred[:,1]\nprint(test1.shape)","execution_count":16,"outputs":[{"output_type":"stream","text":"(306313, 6)\n(306313, 12)\ntorch.Size([306313, 2])\n(306313, 12)\n[[0.9734759  0.02782484]\n [0.8707332  0.13039342]\n [0.8707332  0.13039342]\n ...\n [0.9806337  0.01843761]\n [0.9949628  0.00483484]\n [0.76621515 0.23510157]]\n(306313, 13)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['pred_prob'].max()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"0.28320026"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\nprint(output.shape)\n\noutput.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\noutput.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\noutput.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\noutput[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\noutput.reset_index(drop=True, inplace=True)","execution_count":18,"outputs":[{"output_type":"stream","text":"(306313, 4)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\nout = output.groupby(\"uid\", as_index=False).mean()\nout = out[[\"uid\", \"pred_prob\"]]\nout.columns = [\"uid\", \"label\"]\nout.to_csv(\"prediction.csv\", header=[\"uid\", \"label\"], index=False) # submission format\nout.head(30)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                       uid         label\n0    1000020_2705_20160519  2.351016e-01\n1    1000020_8192_20160513  2.351016e-01\n2    1000065_1455_20160527  9.094165e-02\n3    1000085_8067_20160513  1.481888e-01\n4    1000086_2418_20160613  1.481888e-01\n5    1000140_8192_20160526  2.351016e-01\n6    1000169_2418_20160606  1.481888e-01\n7   1000297_13704_20160520  3.867410e-02\n8   1000324_13165_20160526  5.638128e-02\n9   1000338_10161_20160612  2.828085e-04\n10   1000338_1563_20160523  1.481888e-01\n11   1000345_2427_20160524  8.629432e-02\n12  1000418_11860_20160521  1.973189e-01\n13   1000418_4872_20160506  1.481888e-01\n14   1000452_1613_20160603  1.481888e-01\n15   1000510_4823_20160602  2.351016e-01\n16    1000594_463_20160502  5.038902e-07\n17   1000604_4823_20160602  2.351016e-01\n18   1000621_2418_20160609  7.019286e-02\n19   1000651_2418_20160603  7.019286e-02\n20   1000676_1532_20160519  7.019286e-02\n21   1000676_9875_20160522  1.928549e-01\n22   1000787_4033_20160609  2.351016e-01\n23   1000787_4761_20160523  1.481888e-01\n24   1000832_9122_20160525  7.635565e-02\n25   1000863_1633_20160613  9.664597e-06\n26   1000884_2705_20160508  1.928549e-01\n27   1000884_4823_20160610  2.351016e-01\n28  1000898_11002_20160528  2.979882e-09\n29   1000965_8192_20160525  1.262284e-01","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000020_2705_20160519</td>\n      <td>2.351016e-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000020_8192_20160513</td>\n      <td>2.351016e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000065_1455_20160527</td>\n      <td>9.094165e-02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000085_8067_20160513</td>\n      <td>1.481888e-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000086_2418_20160613</td>\n      <td>1.481888e-01</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1000140_8192_20160526</td>\n      <td>2.351016e-01</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1000169_2418_20160606</td>\n      <td>1.481888e-01</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1000297_13704_20160520</td>\n      <td>3.867410e-02</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1000324_13165_20160526</td>\n      <td>5.638128e-02</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1000338_10161_20160612</td>\n      <td>2.828085e-04</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1000338_1563_20160523</td>\n      <td>1.481888e-01</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1000345_2427_20160524</td>\n      <td>8.629432e-02</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1000418_11860_20160521</td>\n      <td>1.973189e-01</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1000418_4872_20160506</td>\n      <td>1.481888e-01</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1000452_1613_20160603</td>\n      <td>1.481888e-01</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1000510_4823_20160602</td>\n      <td>2.351016e-01</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1000594_463_20160502</td>\n      <td>5.038902e-07</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1000604_4823_20160602</td>\n      <td>2.351016e-01</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1000621_2418_20160609</td>\n      <td>7.019286e-02</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1000651_2418_20160603</td>\n      <td>7.019286e-02</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1000676_1532_20160519</td>\n      <td>7.019286e-02</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1000676_9875_20160522</td>\n      <td>1.928549e-01</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1000787_4033_20160609</td>\n      <td>2.351016e-01</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1000787_4761_20160523</td>\n      <td>1.481888e-01</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1000832_9122_20160525</td>\n      <td>7.635565e-02</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1000863_1633_20160613</td>\n      <td>9.664597e-06</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1000884_2705_20160508</td>\n      <td>1.928549e-01</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1000884_4823_20160610</td>\n      <td>2.351016e-01</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1000898_11002_20160528</td>\n      <td>2.979882e-09</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1000965_8192_20160525</td>\n      <td>1.262284e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}